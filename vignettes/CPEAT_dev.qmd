---
title: "develop new CPEAT"
format: html
---

```{r}
library(tidyverse)

verbose <- TRUE

```

# Single read function

```{r}

read_CPEATfile <- function(filename, 
                           format = c('original', 'long')[1],
                           verbose = FALSE){
  fileread <- read_lines(filename) |>
    paste(collapse = '\n')
  
  
  ##### Parse meta data ####
  
  metaData <- str_extract(fileread, 
                          pattern = regex('(?<=/\\* DATA DESCRIPTION:).*(?=\\*/)',
                                          dotall = TRUE)) |>
    trimws()
  
  temp <- metaData |>
    str_split(pattern = '\n(?!\t)') |>
    unlist() |>
    str_split(pattern = '\t') 
  
  tempNames <- lapply(temp, first)|>
    unlist() |>
    str_remove(regex(':$'))
  
  names(temp) <- tempNames
  
  metaList <- llply(temp, .fun = function(xx){
    ans <- xx[-1] #remove name
    
    if(str_detect(xx[1], 'DATA DESCRIPTION') |
       xx[1] == ""){
      return(NULL)
    }
    
    if(str_detect(xx[1], 'Related to') | 
       str_detect(xx[1], 'Project') |
       str_detect(xx[1], 'Citation') |
       str_detect(xx[1], 'License') |
       str_detect(xx[1], 'Size') |
       str_detect(xx[1], 'Abstract') |
       str_detect(xx[1], 'Keyword') |
       str_detect(xx[1], 'Status') |
       str_detect(xx[1], 'Comment') |
       str_detect(xx[1], 'Further details') |
       str_detect(xx[1], 'Change history')){
      ans <- paste(ans, collapse = '; ')
      return(ans)
    }
    
    if(str_detect(xx[1], 'Event')){
      allEvents <- str_split(ans, pattern = '\\s?\\*\\s?')
      coreName <- unlist(allEvents)[1]
      eventNames <- c('NAME', str_extract(unlist(allEvents)[-1], regex('[^:]*(?=:)')))
      eventValues <- c(list(coreName), str_remove(unlist(allEvents)[-1], regex('[^:]*:\\s*')))
      names(eventValues) <- eventNames
      return(eventValues)
    }
    
    if(str_detect(xx[1], 'Parameter')){
      allParms <- str_split(ans, ' \\* ')
      parameter.ls <- lapply(allParms, function(yy){
        yy_names <- str_remove(yy, regex(':.*$', dotall = TRUE)) |>
          trimws()
        yy_values <- str_extract(yy, regex('(?<=: ).*\\n?$')) |>
          trimws()
        yy_values[1] <- yy_names[1]
        yy_names[1] <- 'description'
        yy_values[is.na(yy_values)] <- TRUE
        setNames(as.list(yy_values), yy_names)
      })
      names(parameter.ls) <- paste0('V', 1:length(parameter.ls))
      
      return(parameter.ls)
    }
    
    if(str_detect(xx[1], 'Coverage')){
      temp2 <- str_split(ans, ' \\* ')|>
        unlist() |>
        trimws()
      allCoverage <- setNames(as.list(str_remove(temp2, '.*: ')), 
                              str_extract(temp2, '.*(?=:)'))
      return(allCoverage)
    }
    
    print(xx)
    stop('Parser flag is not recognized.')
  })
  
  #### Read primary data ####
  
  primaryData <- str_extract(fileread, 
                             pattern = regex('(?<=\\*/\n).*', dotall = TRUE)) |>
    read_tsv(col_types = cols(.default = col_character()),
             name_repair = 'unique_quiet') |>
    mutate(across(.cols = everything(), .fns = trimws))
  
  #### Return orginal format ####
  
  if(format == 'original'){
    return(list(meta = metaList, data = primaryData))
  }
  
  ### Convert to tuple format
  
  meta.df <- as.tibble(as.list(unlist(metaList))) |>
    pivot_longer(cols=everything(), values_to = 'with_entry') |>
    separate_wider_delim(cols = name, delim = '.',
                         names = c('table_name', 'header_name', 'is_type'),
                         too_few = 'align_start') |>
    mutate(header_name = if_else(is.na(header_name), table_name, header_name),
           is_type = if_else(is.na(is_type), 'value', is_type)) |>
    mutate(table_name = if_else(table_name == header_name, '.', table_name)) |>
    mutate(across(.cols = everything(), .fns = trimws))
  
  #if there is only one PI then move that information up from the column level
  if(length(unique(meta.df$with_entry[meta.df$is_type == 'PI'])) == 1){
    meta.df <- meta.df |>
      mutate(header_name = if_else(is_type == 'PI', NA_character_, header_name)) |>
      unique()
  }
  
 
  ## add in the column and row IDs
  temp <- primaryData
  
  #use the traditional R 'V' notation for vertical columns
  column_name.key <- tibble(with_entry = names(primaryData),
                            is_type = 'name',
                            header_name = paste0('V', 1:ncol(primaryData)))
  names(temp) <- column_name.key$header_name
  
  rowIDs <- paste0('R', 1:nrow(primaryData))
  
  temp <- temp |>
    mutate(observation_id = rowIDs) 
  
  data.df <- temp |>
    pivot_longer(cols = -observation_id, 
                 names_to = 'header_name', values_to = 'with_entry') |>
    mutate(is_type = 'value') |>
    bind_rows(column_name.key) |>
    mutate(table_name = 'data')
  
  return(bind_rows(meta.df, data.df))
}

```

# Mock main function

```{r}
dataDir <- '../temp/CPEAT'
annotationFilename <- '../data/annotations_CPEAT3.csv'
format <- c('original', 'long')[1]
verbose <- TRUE


### download files from url

download_urls <- read_delim(file = annotationFilename, 
                            delim = ';', show_col_types = FALSE) |>
  filter(of_variable == 'download_url') |>
  select(download_url = with_entry) |>
  mutate(doi = str_extract(download_url, '10.1594.*\\d')) |>
  mutate(filename = file.path(dataDir, 
                              sprintf('%s.txt', str_replace_all(doi, '/', '_'))))

if(verbose) message(sprintf('Downloading %d of %d files ...',
                            sum(!file.exists(download_urls$filename)),
                            nrow(download_urls)))

for(ii in 1:nrow(download_urls)){
  if(ii %% 50 == 1 & verbose) cat(paste(ii, '... '))
  
  if(!file.exists(download_urls$filename[ii])){
    download.file(download_urls$downloadURL[ii],
                  download_urls$filename[ii],
                  quiet=TRUE)
  }
}

if(verbose) message('Downloads done.')

inputFiles <- list.files(path = dataDir, full.names = TRUE) |>
  as.list()
names(inputFiles) <- str_remove(basename(unlist(inputFiles)), '.txt')

orgData <- llply(inputFiles, .fun = read_CPEATfile, format = 'original')
longData <- ldply(inputFiles, .id = 'doi', .fun = read_CPEATfile, format = 'long')

```

# pull pangaear search dois

```{r}

#searching the repo using the CPEAT project label
pangaearSearchTerm <- "project:label:PAGES_C-PEAT"

# Pangaear only returns top 500 results as a hard max.
# ...coding this up explicitly and then repeating.
pangaear_search <- pangaear::pg_search(pangaearSearchTerm, count = 500) |>  
  #This should only get a total of 876, calling for the entire 500 just incase
  dplyr::bind_rows(pangaear::pg_search(pangaearSearchTerm, 
                                       count = 500, offset = 500)) |>
  #https://doi.pangaea.de/10.1594/PANGAEA.929654?format=textfile
  mutate(downloadURL = sprintf('https://doi.pangaea.de/%s?format=textfile',
                               doi),
         filename = file.path('..', 'temp', 'CPEAT', 
                              sprintf('%s.txt', str_replace_all(doi, '/', '_'))))



```

```{r}
# download files from url

if(verbose) message(sprintf('Downloading %d of %d files ...',
                            sum(!file.exists(pangaear_search$filename)),
                            nrow(pangaear_search)))

for(ii in 1:nrow(pangaear_search)){
  if(ii %% 50 == 1 & verbose) cat(paste(ii, '... '))
  
  if(!file.exists(pangaear_search$filename[ii])){
    download.file(pangaear_search$downloadURL[ii],
                  pangaear_search$filename[ii],
                  quiet=TRUE)
  }
}

if(verbose) message('Downloads done.')

```

# process local files

```{r}

inputFiles <- list.files(path = 'temp/CPEAT', full.names = TRUE) |>
  as.list()
names(inputFiles) <- str_remove(basename(unlist(inputFiles)), '.txt')

#tester1 <- llply(inputFiles, .fun = read_CPEATfile, format = 'original')
tester2 <- ldply(inputFiles, .id = 'doi', .fun = read_CPEATfile, format = 'long')

```

# create meta data

```{r}
#https://doi.pangaea.de/10.1594/PANGAEA.929654?format=textfile
#doi: 10.1594/PANGAEA.929654

parameter.meta <- tester2 |>
  filter(!str_detect(table_name,'data'),
         !str_detect(table_name, 'Parameter')) |>
  select(table_name, header_name, is_type) |>
  mutate(with_entry = '--') |>
  unique() |>
  bind_rows(tibble(of_variable = 'doi',
                   is_type = 'value',
                   with_entry = pangaear_search$doi))

parameters_wide <- tester2 |>
  filter(str_detect(table_name, 'Parameter'),
         str_detect(header_name, '^V\\d+$' )) |>
  select(-observation_id) |>
  dplyr::rename(column_id = header_name) |>
  pivot_wider(names_from = is_type, values_from = with_entry) |>
  mutate(header_name = str_extract(description,
                                 pattern = regex('[^(\\[|\\()]*(?=\\[|\\()')) |>
           trimws() |>
           stringr::str_to_sentence(),
         unit = str_extract(description,
                            pattern = regex('(?<=\\[).*(?=\\])'))|>
           trimws(),
         abreviation = str_extract(description,
                                   pattern = regex('(?<=\\().*(?=\\))'))|>
           trimws()) |>
  #mutate(header_name = case_when(
  #   str_detect(`METHOD/DEVICE`, 'OxCal') ~ paste(header_name, '(OxCal 4.2.4)'),
  #   str_detect(`METHOD/DEVICE`, 'Bacon') ~ paste(header_name, '(Bacon 2.2)'),
  #   str_detect(header_name, '^AGE$') ~ 'Age',
  #   str_detect(header_name, 'Peat type') & !is.na(COMMENT) ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'Method comment') ~ COMMENT,
  #   str_detect(header_name, 'Age, uncertainty') &
  #     str_detect(COMMENT, 'Lab uncertainty') ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'Age, uncertainty') &
  #     str_detect(COMMENT, '(14C age)|(Age AD)') ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'DEPTH') &
  #     str_detect(COMMENT, '(LOI)|(Age)') ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'Age') & str_detect(`METHOD/DEVICE`, '210Pb') ~ paste0(header_name, '(210Pb)'),
  #   str_detect(header_name, 'Age') & str_detect(`METHOD/DEVICE`, 'tephra-chronostratigraphy') ~ paste0(header_name, '(tephra-chronostratigraphy)'), 
  #   .default = header_name)) |>
  #where is description text non-unique in the tables
  #filter(n() > 1, .by = c(doi, header_name))
  unique() |>
  pivot_longer(cols = c(description,
                        GEOCODE, COMMENT, `METHOD/DEVICE`, unit, abreviation),
               names_to = 'is_type',
               values_to = 'with_entry',
               values_drop_na = TRUE)

# column.key <- parameters_wide |>
#   select(doi, header_name, column_id) |>
#   unique()

###data files actions
#remove the parameter table
#join the column.key 
#replace the Parameter table with the processed file
long.df <- tester2 |>
  filter(!str_detect(table_name, 'Parameter')) |>
  dplyr::rename(column_id = header_name) |>
  full_join(parameters_wide |>
              select(doi, header_name, column_id) |>
              unique(), 
            by = join_by(doi, column_id),
            relationship = "many-to-many") |>
  bind_rows(parameters_wide) |>
  mutate(header_name = if_else(is.na(header_name), column_id, header_name)) |>
  mutate(column_id = if_else(header_name == column_id, NA_character_, column_id)) |>
  select(doi, table_name, header_name, column_id, observation_id, is_type, with_entry) 


###annotation files
#identify consistent variables across the project
#append the download urls
coreMeta <- long.df |>
  #look for collection wide metadata
  reframe(org_count = n(),
          unique_count = length(unique(with_entry)),
          #tables = paste(unique(table_name), collapse = ';'),
          .by = c(table_name, header_name, is_type)) |>
  #filter(unique_count == 1) |>
  select(table_name, header_name, is_type) |>
  #mutate(present = '--') |>
  unique() |>
  #pivot_wider(names_from = is_type, values_from = tables) |>
  mutate(of_variable = 
           case_when(header_name %in% "Citation" ~ "citation",
                     header_name %in% "Related to" ~ "related_objects",
                     header_name %in% "Project(s)" ~ "project",
                     header_name %in% "LATITUDE" ~ "latitude",
                     header_name %in% "LONGITUDE" ~ "longitude",
                     header_name %in% "MINIMUM DEPTH, sediment/rock" ~ "core_minimum_depth",#Events
                     header_name %in% "MAXIMUM DEPTH, sediment/rock" ~ "core_maximum_depth",#Events
                     header_name %in% "NAME" ~ "core_name",
                     header_name %in% "LOCATION" ~ "location_name",
                     header_name %in% "METHOD/DEVICE" ~ "core_method",
                     header_name %in% "COMMENT" ~ "core_comment",
                     header_name %in% "License" ~ "data_license",
                     header_name %in% "Size" ~ "data_size",
                     header_name %in% "Depth, sediment/rock" ~ "depth_mid",
                     header_name %in% "Age" ~ "age",
                     header_name %in% "Density, dry bulk" ~ "bulk_density",
                     header_name %in% "Organic matter" ~ "organic_matter",
                     header_name %in% "Density, organic matter" ~ "organic_matter_density",
                     header_name %in% "Density, organic carbon" ~ "organic_carbon_density",
                     header_name %in% "Peat type" ~ "peat_type",
                     header_name %in% "Age, comment" ~ "age",
                     header_name %in% "Sample thickness" ~ "depth_thickness",
                     header_name %in% "Age, dated" ~ "age",
                     header_name %in% "Age, uncertainty" ~ "age_uncertainty",
                     header_name %in% "Age, dated material" ~ "age_material",
                     header_name %in% "Laboratory code/label" ~ "lab_label",
                     header_name %in% "Further details" ~ "core_further_details",
                     header_name %in% "ELEVATION" ~ "elevation",
                     header_name %in% "Recovery" ~ "core_recovery_length",
                     header_name %in% "Carbon, total" ~ "carbon_total",
                     header_name %in% "Penetration" ~ "core_penetration_length",
                     header_name %in% "Nitrogen, total" ~ "nitrogen_total",
                     header_name %in% "ELEVATION START" ~ "elevation_start",
                     header_name %in% "ELEVATION END" ~ "elevation_end",
                     header_name %in% "Activity of radiocarbon in percent of modern carbon" ~ "radiocabon_activity",
                     header_name %in% "Fraction modern carbon" ~ "fraction_modern_carbon",
                     header_name %in% "Calendar age" ~ "age",
                     header_name %in% "Calendar age, maximum/old" ~ "age_maximum",
                     header_name %in% "Calendar age, minimum/young" ~ "age_minimum",
                     header_name %in% "Age, dated standard deviation" ~ "age_standard_deviation",
                     header_name %in% "Age, standard deviation" ~ "age_standard_deviation",
                     header_name %in% "Method comment" ~ "method_comment",
                     header_name %in% "Abstract" ~ "abstract",
                     header_name %in% "Keyword(s)" ~ "keyword",
                     header_name %in% "Status" ~ "curation_status",
                     header_name %in% "Comment" ~ "comment",
                     header_name %in% "Carbon, organic, total" ~ "organic_carbon_total",
                     header_name %in% "Loss on ignition" ~ "loss_on_ignition",
                     header_name %in% "Carbon" ~ "carbon",
                     header_name %in% "Volume" ~ "volume",
                     header_name %in% "Sample volume" ~ "volume",
                     header_name %in% "Sedimentation rate per year" ~ "sedimentation_rate",
                     header_name %in% "Water content, wet mass" ~ "water_content",
                     header_name %in% "Cumulative mass" ~ "cumulative_mass",
                     header_name %in% "Peat carbon accumulation rate per year" ~ "peat_accumulation_rate",
                     header_name %in% "Carbon, inorganic, total" ~ "inorganic_carbon",
                     header_name %in% "Calendar age, standard error" ~ "age_standard_error", 
                     header_name %in% "Sample code/label" ~ "sample_label",
                     header_name %in% "Age model" ~ "age_model",
                     header_name %in% "Age, error" ~ "age_error",
                     header_name %in% "Activity of radiocarbon in percent of modern carbon, standard deviation" ~ "radiocabon_activity_standard_deviation",
                     header_name %in% "Depth, top/min" ~ "depth_top",
                     header_name %in% "Depth, bottom/max" ~ "depth_bottom",
                     header_name %in% "Calendar age, standard deviation" ~ "age_calendar",
                     header_name %in% "Age, relative, number of years" ~ "age_relative",
                     header_name %in% "download_url" ~ "download_url")) |>
  arrange(table_name, of_variable) |>
  mutate(with_entry = '--') |>
  bind_rows(pangaear_search |>
              select(with_entry = downloadURL) |>
              mutate(of_variable = 'download_url',
                     is_type = 'value'))

write_delim(coreMeta, file = '../data/annotations_CPEAT3.csv', delim = ';')
```
