---
title: "develop new CPEAT"
format: html
---

```{r}
library(tidyverse)

verbose <- TRUE

```

# pull pangaear search dois

```{r}
#searching the repo using the CPEAT project label
pangaearSearchTerm <- "project:label:PAGES_C-PEAT"

# Pangaear only returns top 500 results as a hard max.
# ...coding this up explicitly and then repeating.
pangaear_search <- pangaear::pg_search(pangaearSearchTerm, count = 500) |>  
  #This should only get a total of 876, calling for the entire 500 just incase
  dplyr::bind_rows(pangaear::pg_search(pangaearSearchTerm, 
                                       count = 500, offset = 500)) |>
  #https://doi.pangaea.de/10.1594/PANGAEA.929654?format=textfile
  mutate(downloadURL = sprintf('https://doi.pangaea.de/%s?format=textfile',
                               doi),
         filename = file.path('..', 'temp', 'CPEAT', 
                              sprintf('%s.txt', str_replace_all(doi, '/', '_'))))

```

```{r}
# download files from url

if(verbose) message(sprintf('Downloading %d of %d files ...',
                            sum(!file.exists(pangaear_search$filename)),
                            nrow(pangaear_search)))

for(ii in 1:nrow(pangaear_search)){
  if(ii %% 50 == 1 & verbose) cat(paste(ii, '... '))
  
  if(!file.exists(pangaear_search$filename[ii])){
    download.file(pangaear_search$downloadURL[ii],
                  pangaear_search$filename[ii],
                  quiet=TRUE)
  }
}

if(verbose) message('Downloads done.')

```

# process local files

```{r}

inputFiles <- list.files(path = 'temp/CPEAT', full.names = TRUE) |>
  as.list()
names(inputFiles) <- str_remove(basename(unlist(inputFiles)), '.txt')

read_CPEATfile <- function(filename, format = c('original', 'long')[1]){
  fileread <- read_lines(filename) |>
    paste(collapse = '\n')
  
  
  ##### Parse meta data ####
  
  metaData <- str_extract(fileread, 
                          pattern = regex('(?<=/\\* DATA DESCRIPTION:).*(?=\\*/)',
                                          dotall = TRUE)) |>
    trimws()
  
  temp <- metaData |>
    str_split(pattern = '\n(?!\t)') |>
    unlist() |>
    str_split(pattern = '\t') 
  
  tempNames <- lapply(temp, first)|>
    unlist() |>
    str_remove(regex(':$'))
  
  names(temp) <- tempNames
  
  metaList <- llply(temp, .fun = function(xx){
    ans <- xx[-1] #remove name
    
    if(str_detect(xx[1], 'DATA DESCRIPTION') |
       xx[1] == ""){
      return(NULL)
    }
    
    if(str_detect(xx[1], 'Related to') | 
       str_detect(xx[1], 'Project') |
       str_detect(xx[1], 'Citation') |
       str_detect(xx[1], 'License') |
       str_detect(xx[1], 'Size') |
       str_detect(xx[1], 'Abstract') |
       str_detect(xx[1], 'Keyword') |
       str_detect(xx[1], 'Status') |
       str_detect(xx[1], 'Comment') |
       str_detect(xx[1], 'Further details')){
      ans <- paste(ans, collapse = '; ')
      return(ans)
    }
    
    if(str_detect(xx[1], 'Event')){
      allEvents <- str_split(ans, pattern = '\\s?\\*\\s?')
      coreName <- unlist(allEvents)[1]
      eventNames <- c('NAME', str_extract(unlist(allEvents)[-1], regex('[^:]*(?=:)')))
      eventValues <- c(list(coreName), str_remove(unlist(allEvents)[-1], regex('[^:]*:\\s*')))
      names(eventValues) <- eventNames
      return(eventValues)
    }
    
    if(str_detect(xx[1], 'Parameter')){
      allParms <- str_split(ans, ' \\* ')
      parameter.ls <- lapply(allParms, function(yy){
        yy_names <- str_remove(yy, regex(':.*$', dotall = TRUE)) |>
          trimws()
        yy_values <- str_extract(yy, regex('(?<=: ).*\\n?$')) |>
          trimws()
        yy_values[1] <- yy_names[1]
        yy_names[1] <- 'description'
        yy_values[is.na(yy_values)] <- TRUE
        setNames(as.list(yy_values), yy_names)
      })
      names(parameter.ls) <- paste0('V', 1:length(parameter.ls))
      
      return(parameter.ls)
    }
    
    if(str_detect(xx[1], 'Coverage')){
      temp2 <- str_split(ans, ' \\* ')|>
        unlist() |>
        trimws()
      allCoverage <- setNames(as.list(str_remove(temp2, '.*: ')), 
                              str_extract(temp2, '.*(?=:)'))
      return(allCoverage)
    }
    
    print(xx)
    stop('Parser flag is not recognized.')
  })
  
  #### Read primary data ####
  
  primaryData <- str_extract(fileread, 
                             pattern = regex('(?<=\\*/\n).*', dotall = TRUE)) |>
    read_tsv(col_types = cols(.default = col_character()),
             name_repair = 'unique_quiet') |>
    mutate(across(.cols = everything(), .fns = trimws))
  
  #### Return orginal format ####
  
  if(format == 'original'){
    return(list(meta = metaList, data = primaryData))
  }
  
  ### Convert to tuple format
  
  meta.df <- as.tibble(as.list(unlist(metaList))) |>
    pivot_longer(cols=everything(), values_to = 'with_entry') |>
    separate_wider_delim(cols = name, delim = '.',
                         names = c('table_name', 'header_name', 'is_type'),
                         too_few = 'align_start') |>
    mutate(header_name = if_else(is.na(header_name), table_name, header_name),
           is_type = if_else(is.na(is_type), 'value', is_type)) |>
    mutate(table_name = if_else(table_name == header_name, '.', table_name)) |>
    mutate(across(.cols = everything(), .fns = trimws))
  
  #if there is only one PI then move that information up from the column level
  if(length(unique(meta.df$with_entry[meta.df$is_type == 'PI'])) == 1){
    meta.df <- meta.df |>
      mutate(header_name = if_else(is_type == 'PI', NA_character_, header_name)) |>
      unique()
  }
  
  # parameter_renaming <- meta.df |>
  #   filter(str_detect(header_name, '^V\\d+$' )) |>
  #   pivot_wider(names_from = is_type, values_from = with_entry) |>
  #   mutate(name_long = str_extract(description, 
  #                                    pattern = regex('[^(\\[|\\()]*(?=\\[|\\()')),
  #          unit = str_extract(description,
  #                             pattern = regex('(?<=\\[).*(?=\\])')),
  #          abreviation = str_extract(description,
  #                             pattern = regex('(?<=\\().*(?=\\))')))
  # 
  ## add in the column and row IDs
  temp <- primaryData
  
  #use the traditional R 'V' notation for vertical columns
  column_name.key <- tibble(with_entry = names(primaryData),
                            is_type = 'name',
                            header_name = paste0('V', 1:ncol(primaryData)))
  names(temp) <- column_name.key$header_name
  
  rowIDs <- paste0('R', 1:nrow(primaryData))
  
  temp <- temp |>
    mutate(observation_id = rowIDs) 
  
  data.df <- temp |>
    pivot_longer(cols = -observation_id, 
                 names_to = 'header_name', values_to = 'with_entry') |>
    mutate(is_type = 'value') |>
    bind_rows(column_name.key) |>
    mutate(table_name = 'data')
  
  return(bind_rows(meta.df, data.df))
}

#tester1 <- llply(inputFiles, .fun = read_CPEATfile, format = 'original')
tester2 <- ldply(inputFiles, .id = 'doi', .fun = read_CPEATfile, format = 'long')

```

# create meta data

```{r}
#https://doi.pangaea.de/10.1594/PANGAEA.929654?format=textfile
#doi: 10.1594/PANGAEA.929654

parameter.meta <- tester2 |>
  filter(!str_detect(table_name,'data'),
         !str_detect(table_name, 'Parameter')) |>
  select(table_name, header_name, is_type) |>
  mutate(with_entry = '--') |>
  unique() |>
  bind_rows(tibble(of_variable = 'doi',
                   is_type = 'value',
                   with_entry = pangaear_search$doi))

parameters_wide <- tester2 |>
  filter(str_detect(table_name, 'Parameter'),
         str_detect(header_name, '^V\\d+$' )) |>
  select(-observation_id) |>
  dplyr::rename(column_id = header_name) |>
  pivot_wider(names_from = is_type, values_from = with_entry) |>
  mutate(header_name = str_extract(description,
                                 pattern = regex('[^(\\[|\\()]*(?=\\[|\\()')) |>
           trimws() |>
           stringr::str_to_sentence(),
         unit = str_extract(description,
                            pattern = regex('(?<=\\[).*(?=\\])'))|>
           trimws(),
         abreviation = str_extract(description,
                                   pattern = regex('(?<=\\().*(?=\\))'))|>
           trimws()) |>
  #mutate(header_name = case_when(
  #   str_detect(`METHOD/DEVICE`, 'OxCal') ~ paste(header_name, '(OxCal 4.2.4)'),
  #   str_detect(`METHOD/DEVICE`, 'Bacon') ~ paste(header_name, '(Bacon 2.2)'),
  #   str_detect(header_name, '^AGE$') ~ 'Age',
  #   str_detect(header_name, 'Peat type') & !is.na(COMMENT) ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'Method comment') ~ COMMENT,
  #   str_detect(header_name, 'Age, uncertainty') &
  #     str_detect(COMMENT, 'Lab uncertainty') ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'Age, uncertainty') &
  #     str_detect(COMMENT, '(14C age)|(Age AD)') ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'DEPTH') &
  #     str_detect(COMMENT, '(LOI)|(Age)') ~ paste0(header_name, ' (',  COMMENT, ')'),
  #   str_detect(header_name, 'Age') & str_detect(`METHOD/DEVICE`, '210Pb') ~ paste0(header_name, '(210Pb)'),
  #   str_detect(header_name, 'Age') & str_detect(`METHOD/DEVICE`, 'tephra-chronostratigraphy') ~ paste0(header_name, '(tephra-chronostratigraphy)'), 
  #   .default = header_name)) |>
  #where is description text non-unique in the tables
  #filter(n() > 1, .by = c(doi, header_name))
  unique() |>
  pivot_longer(cols = c(description,
                        GEOCODE, COMMENT, `METHOD/DEVICE`, unit, abreviation),
               names_to = 'is_type',
               values_to = 'with_entry',
               values_drop_na = TRUE)

# column.key <- parameters_wide |>
#   select(doi, header_name, column_id) |>
#   unique()

###data files actions
#remove the parameter table
#join the column.key 
#replace the Parameter table with the processed file
long.df <- tester2 |>
  filter(!str_detect(table_name, 'Parameter')) |>
  dplyr::rename(column_id = header_name) |>
  full_join(parameters_wide |>
              select(doi, header_name, column_id) |>
              unique(), 
            by = join_by(doi, column_id),
            relationship = "many-to-many") |>
  bind_rows(parameters_wide) |>
  mutate(header_name = if_else(is.na(header_name), column_id, header_name)) |>
  mutate(column_id = if_else(header_name == column_id, NA_character_, column_id)) |>
  select(doi, table_name, header_name, column_id, observation_id, is_type, with_entry) |>
  bind_rows(pangaear_search |>
              select(doi, with_entry = downloadURL) |>
              mutate(header_name = 'download_url',
                     is_type = 'value'))


###annotation files
#identify consistent variables across the project
#append the download urls
coreMeta <- long.df |>
  #look for collection wide metadata
  reframe(org_count = n(),
          unique_count = length(unique(with_entry)),
          tables = paste(unique(table_name), collapse = ';'),
          .by = c(header_name, is_type)) |>
  #filter(unique_count == 1) |>
  select(tables, header_name, is_type) |>
  #mutate(present = '--') |>
  unique() |>
  pivot_wider(names_from = is_type, values_from = tables)


#replace the VN notation with the Parameter.description text
#add the unit, name, and VN to the parameter table information
```
