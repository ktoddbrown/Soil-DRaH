---
title: "develop new CPEAT"
format: html
---

```{r}
library(tidyverse)
```

# pull pangaear search dois

```{r}
#searching the repo using the CPEAT project label
pangaearSearchTerm <- "project:label:PAGES_C-PEAT"

# Pangaear only returns top 500 results as a hard max.
# ...coding this up explicitly and then repeating.
pangaear_search <- pangaear::pg_search(pangaearSearchTerm, count = 500) |>  
  #This should only get a total of 876, calling for the entire 500 just incase
  dplyr::bind_rows(pangaear::pg_search(pangaearSearchTerm, 
                                       count = 500, offset = 500))
```

# process local files

```{r}

verbose <- TRUE


inputFiles <- list.files(path = 'temp/CPEAT', full.names = TRUE) |>
  as.list()
names(inputFiles) <- str_remove(basename(unlist(inputFiles)), '.txt')

read_CPEATfile <- function(filename, format = c('original', 'long')[1]){
  fileread <- read_lines(filename) |>
    paste(collapse = '\n')
  
  
  ##### Parse meta data ####
  
  metaData <- str_extract(fileread, 
                          pattern = regex('(?<=/\\* DATA DESCRIPTION:).*(?=\\*/)',
                                          dotall = TRUE)) |>
    trimws()
  
  temp <- metaData |>
    str_split(pattern = '\n(?!\t)') |>
    unlist() |>
    str_split(pattern = '\t') 
  
  tempNames <- lapply(temp, first)|>
    unlist() |>
    str_remove(regex(':$'))
  
  names(temp) <- tempNames
  
  metaList <- llply(temp, .fun = function(xx){
    ans <- xx[-1] #remove name
    
    if(str_detect(xx[1], 'DATA DESCRIPTION') |
       xx[1] == ""){
      return(NULL)
    }
    
    if(str_detect(xx[1], 'Related to') | 
       str_detect(xx[1], 'Project') |
       str_detect(xx[1], 'Citation') |
       str_detect(xx[1], 'License') |
       str_detect(xx[1], 'Size') |
       str_detect(xx[1], 'Abstract') |
       str_detect(xx[1], 'Keyword') |
       str_detect(xx[1], 'Status') |
       str_detect(xx[1], 'Comment') |
       str_detect(xx[1], 'Further details')){
      ans <- paste(ans, collapse = '; ')
      return(ans)
    }
    
    if(str_detect(xx[1], 'Event')){
      allEvents <- str_split(ans, pattern = '\\s?\\*\\s?')
      coreName <- unlist(allEvents)[1]
      eventNames <- c('NAME', str_extract(unlist(allEvents)[-1], regex('[^:]*(?=:)')))
      eventValues <- c(list(coreName), str_remove(unlist(allEvents)[-1], regex('[^:]*:\\s*')))
      names(eventValues) <- eventNames
      return(eventValues)
    }
    
    if(str_detect(xx[1], 'Parameter')){
      allParms <- str_split(ans, ' \\* ')
      parameter.ls <- lapply(allParms, function(yy){
        yy_names <- str_remove(yy, regex(':.*$', dotall = TRUE)) |>
          trimws()
        yy_values <- str_extract(yy, regex('(?<=: ).*\\n?$')) |>
          trimws()
        yy_values[1] <- yy_names[1]
        yy_names[1] <- 'description'
        yy_values[is.na(yy_values)] <- TRUE
        setNames(as.list(yy_values), yy_names)
      })
      names(parameter.ls) <- paste0('V', 1:length(parameter.ls))
      
      return(parameter.ls)
    }
    
    if(str_detect(xx[1], 'Coverage')){
      temp2 <- str_split(ans, ' \\* ')|>
        unlist() |>
        trimws()
      allCoverage <- setNames(as.list(str_remove(temp2, '.*: ')), 
                              str_extract(temp2, '.*(?=:)'))
      return(allCoverage)
    }
    
    print(xx)
    stop('Parser flag is not recognized.')
  })
  
  #### Read primary data ####
  
  primaryData <- str_extract(fileread, 
                             pattern = regex('(?<=\\*/\n).*', dotall = TRUE)) |>
    read_tsv(col_types = cols(.default = col_character()),
             name_repair = 'unique_quiet') 
  
  #### Return orginal format ####
  
  if(format == 'original'){
    return(list(meta = metaList, data = primaryData))
  }
  
  ### Convert to tuple format
  
  meta.df <- as.tibble(as.list(unlist(metaList))) |>
    pivot_longer(cols=everything(), values_to = 'with_entry') |>
    separate_wider_delim(cols = name, delim = '.',
                         names = c('table_name', 'header_name', 'is_type'),
                         too_few = 'align_start') |>
    mutate(header_name = if_else(is.na(header_name), table_name, header_name),
           is_type = if_else(is.na(is_type), 'value', is_type)) |>
    mutate(table_name = if_else(table_name == header_name, '.', table_name))
  
  if(length(unique(meta.df$with_entry[meta.df$is_type == 'PI'])) == 1){
    meta.df <- meta.df |>
      mutate(header_name = if_else(is_type == 'PI', NA_character_, header_name)) |>
      unique()
  }
  
  ## add in the column and row IDs
  temp <- primaryData
  #use the traditional R 'V' notation for vertical columns
  column_name.key <- tibble(with_entry = names(primaryData),
                            is_type = 'name',
                            header_name = paste0('V', 1:ncol(primaryData)))
  names(temp) <- column_name.key$header_name
  
  rowIDs <- paste0('R', 1:nrow(primaryData))
  
  temp <- temp |>
    mutate(observation_id = rowIDs) 
  
  data.df <- temp |>
    pivot_longer(cols = -observation_id, 
                 names_to = 'header_name', values_to = 'with_entry') |>
    mutate(is_type = 'value') |>
    bind_rows(column_name.key) |>
    mutate(table_name = 'data')
  
  return(bind_rows(meta.df, data.df))
}

#tester1 <- llply(inputFiles, .fun = read_CPEATfile, format = 'original')
tester2 <- ldply(inputFiles, .id = 'doi', .fun = read_CPEATfile, format = 'long')

```

# create meta data

```{r}
#https://doi.pangaea.de/10.1594/PANGAEA.929654?format=textfile
#doi: 10.1594/PANGAEA.929654


```
