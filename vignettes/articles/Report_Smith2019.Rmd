---
title: "Report_Smith2019"
output: html_document
date: "7/6/24"
---

<style type="text/css">
.main-container {
  max-width: 100% !important;
  margin: auto;
}
</style>

<body style="background-color: #ECECEC;">

The purpose of this document is to summarize the portions of the United States Geological Survey's AHorizons Database that are relevant to data collections in the SoilDRaH project and walk through the data ingestion. Here you will find links to documentation from the data provider, links to where you can access the data, a description of how the data was processed, and visuals for the collection relevant variables.

Data annotations
----------------
This lab's annotation generation process results in a csv file with the following column format: table_id,column_id,of_variable,is_type,with_entry. The table_id is generally the base name of the csv/tsv file that is associated with the column_id, which is an exact match for the names of the columns in the associated tables. Entries in the of_variable column describe the variables that is associated with the id. These are generally observable properties like bulk density, organic carbon, ecotype, or soil color. The is_type entry commonly falls into one of the following {value, definition, unit, method, control_vocabulary}. This describes the kind of information associated with of_variable that is found in the with_entry. The with_entry column is either the entry associated with the variable and type described above or a special notation that indicates you should refer to the data set being described. We currently use -- for data set reference.

The following is the code that generated the Smith 2019 annotations.
```{r annotations, eval=FALSE}
library(readxl)
library(tibble)
library(dplyr)
library(stringr)

# Dev variable to the path of the file directory that stores your Smith2019 data set
# file_dir <- "C:/Users/gthra/Coding/Research Lab - Summer 2024/Annotations/AHorizons Annotations"

# Set file attributes for smith2019 data set
base_file_name <- "Appendix_3a_Ahorizon_18Sept2013"
file_path <- paste0(file_dir, "/", base_file_name, ".xlsx")

# Read in the metadata -- which contains certain column descriptions and control vocabulary, table-wide note and control vocabulary-- and remove 
# the square brackets ([]) that surround it
metadata.df <- rename(read_xlsx(file_path, col_names=FALSE, range="A_Horizon!A3:A10"), c("info"=...1))
metadata.df[1, 1] <- str_extract(metadata.df[1, 1], stringr::regex("[^\\[].*"))
metadata.df[8, 1] <- str_extract(metadata.df[8, 1], stringr::regex("[^\\]]*"))

# Get the column_id to description "map" table which will be joined with the main annotations table later
description <- 
  tribble(~description, paste(paste(str_extract(metadata.df[1, 1], stringr::regex("LabID[^:]*")), metadata.df[4, 1], sep="; "), 
                              metadata.df[5, 1], metadata.df[6, 1], str_extract(metadata.df[7, 1], stringr::regex("^(?:(?!; cm).)*")), sep=" ")) %>% 
  tidyr::separate_longer_delim(description, "; ") %>% 
  tidyr::separate_wider_delim(description, ", ", names=c("column_id", "description")) %>% 
  mutate(column_id = ifelse(column_id %in% c("SiteID", "StateID", "Latitude", "Longitude", "CollDate", "LandCover1", "LandCover2"), column_id, paste0("A_", column_id)))

# Generate the filtered, long-style carbon annotations table by (1) reading in column names, descriptions, control vocabulary, and units into a wide table format, 
# (2) adding in the table_id, of_variable, value, and identifier, (3) splitting some descriptions from control vocabulary, (4) then pivoting to a long format while 
# (5) adding the table-wide note.
smith2019_annotations <- 
  rename(as_tibble(t(read_xlsx(file_path, col_names=FALSE, range="A_Horizon!A13:CD14"))), c("column_id"=V1, "unit"=V2)) %>% 
  mutate(
    table_id = base_file_name,
    value = "--",
    identifier = "--",
    # Column_id to of_variable map
    of_variable = case_when(
      column_id %in% c("A_LabID", "SiteID") ~ "Unique_identifier",
      column_id %in% c("StateID") ~ "State identifier",
      column_id %in% c("Latitude") ~ "Latitude",
      column_id %in% c("Longitude") ~ "Longitude",
      column_id %in% c("CollDate") ~ "Date_sampled",
      column_id %in% c("LandCover1", "LandCover2") ~ "NLC_database_land_classification",
      column_id %in% c("A_Depth") ~ "A_horizon_depth",
      # column_id involves an element of the periodic table (column_id == 3 or 4 -> column_id is "A_{periodic table element abbreviation}")
      nchar(column_id) %in% c(3, 4) ~ "A_horizon_element_composition",
      # True = any column_id not mentioned (mapped from) above 
      TRUE ~ "A_horizon_soil_composition"),
    control_vocabulary = ifelse(column_id == "StateID", str_replace_all(str_extract(paste(str_extract(metadata.df[1, 1], stringr::regex("AL.*$")), metadata.df[2, 1], metadata.df[3, 1], sep = " "), stringr::regex(".*(?=;)")), ", ", "|"), NA)
  ) %>% 
  # Join the description table with smith2019_annotations table, populating the descriptions of the columns with column_ids given
  left_join(description) %>% 
  # Reorder the columns' positions to the lab's is_type order
  select(table_id, column_id, of_variable, value, description, unit, control_vocabulary, identifier) %>%
  # Pivot longer and add in the table note and control vocabulary
  tidyr::pivot_longer(c("value", "description", "unit", "control_vocabulary", "identifier"), names_to = "is_type", values_to = "with_entry", values_drop_na=TRUE) %>%
  add_row(table_id=base_file_name, column_id=NA, of_variable=NA, is_type="note", with_entry=as.character(str_extract(metadata.df[1, 1], stringr::regex("^[^;]*"))), .before=1) %>%
  add_row(table_id=base_file_name, column_id=NA, of_variable=NA, is_type="control_vocabulary", with_entry=as.character(str_replace_all(paste(str_extract(metadata.df[7, 1], stringr::regex("cm.*")), metadata.df[8, 1], sep=" "), ", ", "|")), .before=2)

# Write smith2019_annotations to a csv file
write.csv(smith2019_annotations, "Smith2019 annotations.csv", quote=FALSE, row.names=FALSE)
```

</body>