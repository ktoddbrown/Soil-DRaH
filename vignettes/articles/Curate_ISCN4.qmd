---
title: "Curation of ISCN4"
author: "Kathe Todd-Brown"
format:
  html:
    toc: true
    number-sections: true
    code-fold: true
    code-summary: "Show the code"
---

This document works through creating a data product of layer-level soil organic carbon profiles (with both observation times recorded and location where possible) from the USDA-FS-FIA Database, ISCN3, and the USDA-NRCS-NCSS Database.

A brief word of warning, the size of these databases can be considerable for some computers (<10 GBs).
This code is designed to be run locally on a machine that has the capasity to download and work with this filesize.
If your computer is primarily scoped for working with text documents and a few spreadsheets, you may not be able to run this code.
This code uses the `tidyverse` and `RSQLite` packages with additional formating support from `knitr` and `kableExtra`.


```{r setup, message=FALSE, warning=FALSE}
#| code-summary: "Setup"

library(tidyverse) #data structure manipulation
library(RSQLite) #accessing the NCSS sql library
library(knitr) # make prettier tables
library(kableExtra) #make tables scroll-able

RscriptsDir <- '../../R'
annotationsDir <- '../../data'
dataDownloadDir <- '../../temp'

#Note that if these change you should also go down and update the appedix read chunks
databaseReads <- list(FIA = 'readFIA.R',
                      ISCN3 = 'readISCN3.R',
                      NCSS = 'readNCSS.R')

annotationFiles <- list(FIA = 'FIA_Annotations.csv',
                        ISCN3 = 'ISCN3Annotations.csv',
                        NCSS = 'NCSS_Annotations.csv')

source(file.path(RscriptsDir, databaseReads$ISCN3))
source(file.path(RscriptsDir, databaseReads$FIA))

#knitr::opts_chunk$set(collapse = TRUE)
```

```{r echo=FALSE}
#Set this to any alternative download directory
dataDownloadDir <- '~/Dropbox (UFL)/Research/Datasets'
```

# Data sources

## ISCN3

### Read in ISCN3

```{r readISCN3}
iscn.ls <- readISCN3(dataDir = file.path(dataDownloadDir, '/ISCN3'),
                     annotationFilename = file.path(annotationsDir, annotationFiles$ISCN3),
                     format = 'long',
                     verbose = FALSE) #swicth to TRUE for dev
```


### Trim the dataset

```{r}
#Use the annotations to set up the column selection
ISCN3_column_selection <- iscn.ls$annotation |>
  filter((of_variable %in% c('latitude', 'longitude',
                            'state', 'country') & table_id == 'layer') |
         (table_id == 'layer' & 
         (of_variable %in% c('layer_observation_time',
                            'upper_depth_bound', 'lower_depth_bound',
                            'organic_carbon', 'coarse_fragment') |
  str_detect(of_variable, 'bulk_density')))) |>
  filter(with_entry == '--') |>
  select(ends_with('_id'), of_variable, is_type)

metadata.df <- iscn.ls$annotation |>
  semi_join(ISCN3_column_selection |>
              select(table_id, column_id, of_variable) |>
              unique(),
            by = join_by(table_id, column_id, of_variable)) |>
  filter(with_entry != '--') |>
  select(study_id, of_variable, is_type, with_entry)

# Subset the ISCN database
temp.df <- iscn.ls$long |> 
  ##nrow 17 967 513
  filter(!str_detect(dataset_id, 'NRCS'), #remove the old NCSS data
         !str_detect(soc_id, 'ISCN SOC stock'), #remove so we can recalculate the SOC stocks
         !str_detect(soc_id, 'AK DSC Project SOC')) |> #remove so we can recalculate the SOC stocks
  ##nrow 1 043 250
  # use the column selection to subset the database
  right_join(ISCN3_column_selection, 
             relationship = "many-to-many",
  by = join_by(column_id, table_id)) |>
  ##nrow 454 994
  select(table_id, column_id, study_id, dataset_id, profile_id, layer_id, soc_id, of_variable, is_type, with_entry)

surface_location.df <- temp.df |>
  filter(of_variable %in% c('latitude', 'longitude',
                            'state', 'country', 
                            'layer_observation_time')) |>
  select(study_id, dataset_id, profile_id,
         of_variable, is_type, with_entry) |>
  ## nrow 197 081
  unique() 
  ## nrow 41 325

layer.df <- temp.df |>
  filter(! of_variable %in% c('latitude', 'longitude',
                              'state', 'country', 
                              'layer_observation_time')) |>
  select(study_id, dataset_id, profile_id, layer_id,
         of_variable, is_type, with_entry) |>
  ##nrow 258 913
  unique() #removing duplicates imposed by legacy soc calculations associated with soc_id
  ##nrow 257 506

#memory management
rm(temp.df, ISCN3_column_selection, iscn.ls) #comment out for dev
```

From this we carry forward three tables

```{r exampleMeta}
#| code-summary: 'metadata'
#| code-fold: true

knitr::kable(metadata.df) |>
  kable_paper() |>
  scroll_box(width = "100%", height = "300px")

```

```{r exampleGeo}
#| code-summary: 'geolocation (surface)'
#| code-fold: true

knitr::kable(surface_location.df |>
               slice_head(n=200)) |>
  kable_paper() |>
  scroll_box(width = "100%", height = "300px")

```

```{r exampleLayer}
#| code-summary: 'layer'
#| code-fold: true

knitr::kable(layer.df |>
               slice_head(n=200)) |>
  kable_paper() |>
  scroll_box(width = "100%", height = "300px")

```

## Forest Inventory Analysis Database (USDA-FS)

```{r}
fia.ls <- readFIA(file.path(dataDownloadDir, 'FS_FIA'), 
                  annotationFilename = file.path(annotationsDir, annotationFiles$FIA), 
                  verbose = FALSE, #when first running, switch this to true 
                  format = 'long')
#The FIA data base object is large, 2.3 GB
```

```{r}

FIA_column_selection <- fia.ls$annotations |>
  #identify the variables that we are interested in
  filter(of_variable %in% c(
             'Inventory_year',
             'Longtitude', 'Latitude', 'State',
             'Layer_type',
             'Bulk_density',
             'coarse_fraction',
             'organic_carbon',
             'carbon_fraction',
             'inorganic_carbon'),
         #limit these to tables since some of them are duplicates
         table_id %in% c('ENTIRE_PLOT', 'ENTIRE_SOILS_LAB'),
         is_type != 'identifier',
         #only look at those that map to the data as marked by '--'
         with_entry == '--') |>
  #create a table for exclusive join
  select(table_id, column_id, of_variable, is_type)

FIA_meta.df <- fia.ls$annotations |>
  semi_join(FIA_column_selection |>
              select(of_variable) |>
              unique(),
            by = join_by(of_variable)) |>
  filter(with_entry != '--')

temp.df <- FIA_column_selection |>
  #down select the data that matches the variables of interest above
  inner_join(fia.ls$long, # |>slice_head(n = 1e3),
            by = join_by(table_id, column_id),
            relationship = "many-to-many") 

FIA_location.df <- temp.df |>
  filter(of_variable %in% c(
             'Inventory_year',
             'Longtitude', 'Latitude', 'State')) |>
  ##nrow 1 611 054
  select(plot_id = CN.ENTIRE_PLOT, of_variable, is_type, with_entry) |>
  unique()
  ##nrow 24 284
  ###Dev code: check unique location identifier
  #reframe(count = n(), #all counts should be 1
  #        .by = c(plot_id, of_variable, is_type)) |> summary()

FIA_layer.df <- temp.df |>
  filter(of_variable %in% c('Layer_type',
                            'Bulk_density',
                            'coarse_fraction',
                            'organic_carbon',
                            'carbon_fraction',
                            'inorganic_carbon')) |>
  #nrow 1 220 058
  select(plot_id = CN.ENTIRE_PLOT, layer_id = CN.ENTIRE_SOILS_LAB, 
         of_variable, is_type, with_entry) |>
  unique() #|>
  #nrow   105 238
  ###Dev code: check unique location identifier
  #reframe(count = n(), #all counts should be 1
  #        .by = c(ends_with('_id'), of_variable, is_type)) |> summary()

#memory management
rm(temp.df, FIA_column_selection, fia.ls) #comment out for dev
```

# Bind data sources

```{r}
allmeta.df <- metadata.df |>
  mutate(study_id = 'ISCN3') |>
  bind_rows(FIA_meta.df |> #drop column_id
              mutate(study_id = 'FIA')) |>
  select(study_id, of_variable, is_type, with_entry) |>
  unique()

#names(surface_location.df) #[1] "study_id" "dataset_id"  "profile_id"  "of_variable" "is_type" "with_entry" 
alllocation.df <- surface_location.df |>
  bind_rows(FIA_location.df |> #names(FIA_location.df) #[1] "plot_id" "of_variable" "is_type" "with_entry" 
              mutate(study_id = 'FIA'))

alllayer.df <- layer.df |>
  bind_rows(FIA_layer.df |> #names(FIA_layer.df) #[1] "plot_id" "layer_id" "of_variable" "is_type" "with_entry" 
              mutate(study_id = 'FIA'))

#memory management
rm(layer.df, FIA_layer.df, surface_location.df, FIA_location.df, metadata.df, FIA_meta.df)
```

# Method harmonization

```{r}

#Construct a table of everything that is not a value from all three tables

notValue <- allmeta.df |>
  filter(!is_type %in% c('identifier', 'value')) |>
  bind_rows(alllocation.df |>
              filter(!is_type %in% c('identifier', 'value'))) |>
  bind_rows(alllayer.df |>
              filter(!is_type %in% c('identifier', 'value'))) |>
  select(study_id, of_variable, is_type, with_entry) |>
  unique() |>
  pivot_wider(names_from = is_type,
              values_from = with_entry,
              values_fn = function(xx){
                paste(xx, collapse = '::\n ')
              })
  
```


```{r}
#| code-fold: true

knitr::kable(notValue) |>
  #kable_paper() |>
  scroll_box(width = "100%", height = "300px")

```

Examining the contextual metadata we need to do the following:

  + country and state
    * FIA: Extract the control vocabulary and substitute it into those entries
    * All: Ensure consistent state and country names (capitalization and convention)
  + latitude and longitude
    * All: Check for upper/lower bounds (latitude -180:180, longitude -90:90)
    * All: populate datum for each value or label as unknown
  + layer depth
    * FIA: populate upper and lower bounds from control vocabulary
    * All: check zero location
    * All: convert to units to cm
  + observation year
    * ISCN3: convert from days since origin (unless under 2100)
  + bulk density
    * ISCN3: remove known fine earth bulk density
    * All: convert units to g cm-3
    * All: move over method notes to primary data
  + organic carbon, inorganic carbon, and coarse fraction
    * All: convert units to mass-percent
    * All: move over method notes to primary data

## Country and state

```{r}
ISCNcountry.df <- alllocation.df |>
  filter(of_variable %in% 'country',
         is_type == 'value') |>
  mutate(with_entry = if_else(with_entry == 'Unknown', NA_character_, with_entry)) |>
  pivot_wider(names_from = of_variable, values_from = with_entry) |>
  filter(!is.na(country))

FIAcountry.df <- alllocation.df |>
  filter(study_id == 'FIA') |>
  select(ends_with('_id')) |>
  mutate(country = 'United States') # All FIA sites are within the US

FIAstate.key <- allmeta.df |>
  filter(study_id == 'FIA',
         is_type == 'control_vocabulary',
         of_variable == 'State') |>
  tidyr::separate_longer_delim(with_entry, delim = ';') |>
  tidyr::separate_wider_delim(with_entry, delim = '|', names = c('key', 'value')) |>
  select(key, value)

FIAstate.df <- alllocation.df |>
  filter(of_variable %in% c('state', 'State'),
         is_type == 'value',
         study_id == 'FIA') |>
  left_join(FIAstate.key, by = join_by(with_entry == key)) |>
  select(study_id, plot_id, state = value)
  
ISCNstate.df <- alllocation.df |>
  filter(of_variable %in% c('state', 'State'),
         is_type == 'value',
         study_id == 'ISCN3') |>
  select(study_id, dataset_id, profile_id, state = with_entry) |>
  mutate(state = if_else(state == 'Unknown', NA_character_, state)) |>
  filter(!is.na(state))

# manual check that differences are not format errors
#setdiff(unique(FIAstate.df$state), unique(ISCNstate.df$state))
#setdiff(unique(ISCNstate.df$state), unique(FIAstate.df$state))
# manually check states are US states
#unique(ISCNstate.df$state)

dataRegions.df <- ISCNstate.df |>
  bind_rows(FIAstate.df) |>
  full_join(ISCNcountry.df |>
              bind_rows(FIAcountry.df),
            by = join_by(study_id, dataset_id, profile_id, plot_id)) |>
  mutate(country = if_else(!is.na(state) & is.na(country), 'United States', country)) |>
  select(study_id, dataset_id, profile_id, plot_id, country, state) |>
  mutate(across(.cols = c(state, country), as.factor))

metaRegions.df <- tribble(~of_variable, ~is_type, ~with_entry,
                          'state', 'value', '--',
                          'state', 'description', 'state name within the US',
                          'country', 'value', '--',
                          'country', 'description', 'country name')

rm(FIAcountry.df, FIAstate.df, ISCNcountry.df, ISCNstate.df, FIAstate.key)
```

### Country tally

```{r}
dataRegions.df |>
  reframe(count = n(), .by = c(country)) |>
  arrange(desc(count)) |>
  kable () |>
  #kable_paper() |>
  scroll_box(width = "100%", height = "300px")
```

### State tally

```{r}
dataRegions.df |>
  filter(!is.na(state)) |>
  reframe(count = n(), .by = c(country, state)) |>
  arrange(desc(count)) |>
  kable () |>
  #kable_paper() |>
  scroll_box(width = "100%", height = "300px")
```

## latitued and longitude

```{r}
ref <- allmeta.df %>%
  filter(str_detect(string = of_variable, pattern = '.atitude') |
           str_detect(string = of_variable, pattern = '.ongt?itude'))

#all latitude/longitude should be in decimal degrees centered on 0
#FIA datum is based on state code:
# "The approximate latitude of the plot in decimal degrees using NAD 83 datum (these Pacific Islands plots use WSG84 datum - SURVEY.RSCD = 26 and SURVEY.STATECD = 60, 64, 66, 68, 69, or 70). Actual plot coordinates cannot be released because of a Privacy provision enacted by Congress in the Food Security Act of 1985. Therefore, this attribute is approximately +/- 1 mile and, for annual inventory data, most plots are within +/- ½ mile. Annual data have additional uncertainty for private plots caused by swapping plot coordinates for up to 20 percent of the plots. In some cases, the county centroid is used when the actual coordinate is not available."

FIAdatum <- alllocation.df %>%
  filter(study_id == 'FIA',
         is_type == 'value',
         of_variable == 'State') %>%
  #the with_entry is now the STATECD
  mutate(datum = if_else(with_entry %in% c('60', '64', '66', '68', '69', '70'), 
                         'WSG84', 'NAD83')) %>%
  #Note that there are currently no locations with these state codes - 20240622
  select(study_id, plot_id, datum) %>%
  unique()

ISCNdatum <- alllocation.df %>%
  filter(study_id == 'ISCN3', 
         is_type == 'method') %>% #all the methods here are datums
  select(study_id, dataset_id, profile_id, datum = with_entry) %>%
  unique() 

latLon.df <- alllocation.df %>%
  filter(str_detect(of_variable, pattern = '.atitude') |
           str_detect(of_variable, pattern = '.ongt?itude'),
         is_type == 'value') %>%
  mutate(header_name = if_else(str_detect(of_variable, pattern = '.atitude'), 
                               'latitude', 'longitude')) %>%
  select(ends_with('_id'), header_name, with_entry) %>%
  pivot_wider(names_from = header_name, values_from = with_entry) %>%
  mutate(across(.cols = c(latitude, longitude), as.numeric)) %>%
  #check for bounds, nothing to remove
  left_join(bind_rows(FIAdatum, ISCNdatum),
            by = join_by(study_id, dataset_id, profile_id, plot_id)) %>%
  mutate(across(.cols = datum, as.factor))

#dummy check to future proof changes
if(any(latLon.df$latitude > 90 | latLon.df$latitude < -90 |
   latLon.df$longitude > 180 | latLon.df$longitude < -180)){
  stop('out of bounds lat-lon')
}
  
metaLatLon.df <- tribble(~study_id, ~of_variable, ~is_type, ~with_entry,
                         NA, 'latitude', 'value', '--',
                         NA, 'latitude', 'unit', 'decimal degrees centered on zero',
                         'FIA', 'latitude', 'note', "Actual plot coordinates cannot be released because of a Privacy provision enacted by Congress in the Food Security Act of 1985. Therefore, this attribute is approximately +/- 1 mile and, for annual inventory data, most plots are within +/- ½ mile. Annual data have additional uncertainty for private plots caused by swapping plot coordinates for up to 20 percent of the plots. In some cases, the county centroid is used when the actual coordinate is not available.",
                         NA, 'longitude', 'value', '--',
                         NA, 'longitude', 'unit', 'decimal degrees centered on zero',
                         'FIA', 'longitude', 'note', "Actual plot coordinates cannot be released because of a Privacy provision enacted by Congress in the Food Security Act of 1985. Therefore, this attribute is approximately +/- 1 mile and, for annual inventory data, most plots are within +/- ½ mile. Annual data have additional uncertainty for private plots caused by swapping plot coordinates for up to 20 percent of the plots. In some cases, the county centroid is used when the actual coordinate is not available.",
                         NA, 'datum', 'value', '--',
                         NA, 'datum', 'description', 'Geospacial datum reference for latitude and longitude')

rm(ISCNdatum, FIAdatum, ref)
```


Note that the FIA database currently does not have soil observations for the state codes associated with `WSG84`.

### Latitude and longitude summary

```{r}
latLon.df %>%
  reframe(count = n(), .by = c(study_id, datum)) |>
  kable () |>
  #kable_paper() |>
  scroll_box(width = "100%", height = "300px")
```

```{r}
latLon.df |>
  select(-ends_with('id')) |>
  summary()
```

## observation year

```{r}
ref <- allmeta.df |>
  filter(of_variable %in% c('layer_observation_time', 'Inventory_year' ))

observationYr.df <- alllocation.df |>
  filter(of_variable %in% c('layer_observation_time', 'Inventory_year' ),
         is_type == 'value') |> #check that there are no units or other items here
  mutate(with_entry = as.numeric(with_entry)) |>
  mutate(observation_year = if_else(with_entry < 2300, #assuming no obs before 1906-04-20
                                    with_entry,
                                    year(lubridate::as_date(with_entry, 
                                                            origin = ymd('1900-01-01'))))) %>%
  select(ends_with('_id'), observation_year)

metaObsYr <- tribble(~of_variable, ~is_type, ~with_entry,
                     'observation_year', 'value', '--',
                     'observation_year', 'description', 'best guess for year closed to sampling date')
```

```{r}
ggplot(observationYr.df) +
  geom_histogram(aes(x=observation_year), binwidth = 1) +
  facet_wrap(~study_id, ncol=1, scales = 'free_y')
```

## Layer depth interval

```{r}
ref <- allmeta.df |>
  filter(of_variable %in% c("Layer_type",
                            "lower_depth_bound", "upper_depth_bound"))

FIAkey <- ref |>
  filter(is_type == 'control_vocabulary')  |>
  select(with_entry) |>
  tidyr::separate_longer_delim(with_entry, delim = ';') |>
  tidyr::separate_wider_delim(with_entry, delim = '|', names = c('key', 'value')) |>
  select(key, value) |>
  mutate(lower_depth_bound = case_when(str_detect(value, '0-4 inch') ~ 4*2.54, #convert to cm
                                       str_detect(value, '4-8 inch') ~ 8*2.54,
                                       TRUE ~ NA),
         upper_depth_bound = case_when(str_detect(value, '0-4 inch') ~ 0*2.54,
                                       str_detect(value, '4-8 inch') ~ 4*2.54,
                                       TRUE ~ NA))

FIAdepth <- alllayer.df |>
  filter(of_variable %in% c("Layer_type")) |>
  full_join(FIAkey, by = join_by(with_entry == key)) |>
  select(study_id, plot_id, layer_id, upper_depth_bound, lower_depth_bound)

ISCNdepth <- alllayer.df %>%
  filter(of_variable %in% c("lower_depth_bound", "upper_depth_bound")) %>%
  filter(is_type == 'value') |>
  #TODO: Worldwide soil carbon and ... needs to be address in readISCN
  # dplyr::reframe(n = dplyr::n(), 
  #                  entries = paste(with_entry, collapse = '::'),
  #                  .by = c(study_id, dataset_id, profile_id, layer_id,
  # is_type, plot_id, of_variable)) |>
  # dplyr::filter(n > 1L)
  pivot_wider(names_from = of_variable, values_from = with_entry,
              values_fn = function(xx){
                if(length(xx) > 1){
                  return(c(NA)) #drop ambiguous data, known issue with ISCN
                }else{
                  return(xx)
                }
              }) %>%
  select(study_id, dataset_id, profile_id, layer_id, upper_depth_bound, lower_depth_bound) %>%
  mutate(across(c(upper_depth_bound, lower_depth_bound), as.numeric))

depth.df <- ISCNdepth |>
  bind_rows(FIAdepth)

metaDepth.df <- tribble(~study_id, ~of_variable, ~is_type, ~with_entry,
                         NA, 'upper_depth_bound', 'value', '--',
                         NA, 'upper_depth_bound', 'unit', 'cm',
                         NA, 'upper_depth_bound', 'description', 'depth to upper layer bound from surface',
                         NA, 'lower_depth_bound', 'value', '--',
                         NA, 'lower_depth_bound', 'unit', 'cm',
                         NA, 'lower_depth_bound', 'description', 'depth to lower layer bound from surface',
)
```

## Bulk density

```{r}
ref <- allmeta.df |>
  dplyr::filter(str_detect(string = of_variable,
                    pattern = 'ulk_density')) |>
  pivot_wider(names_from='is_type', values_from = 'with_entry',
              values_fn = function(xx)paste(xx, collapse = '::'))

mapping_bulk_density <- tribble(
  ~study_id, ~of_variable, ~header_str, ~description, ~method,
  'ISCN3', 'bulk_density_sample', 'bulk_density_fine', 'fine earth bulk density, <2mm', 'measured',
  'ISCN3', 'bulk_density_total', 'bulk_density_whole', 'whole soil bulk density', 'measured',
  'ISCN3', 'bulk_density_whole', 'bulk_density_whole', 'whole soil bulk density', 'estimated',
  'ISCN3', 'bulk_density_other', 'bulk_density_unknown', 'whole or fine soil bulk density', 'unknown',
  'FIA', 'Bulk_density', 'bulk_density_whole', 'whole soil bulk density', 'measured') %>%
  mutate(unit = 'g cm-3')

bulk_density.df <- alllayer.df |>
  dplyr::filter(of_variable %in% mapping_bulk_density$of_variable) |>
  mutate(is_type = if_else(is_type == 'method', 'note', is_type)) |>
  pivot_wider(names_from = is_type, values_from = with_entry,
              values_fn = function(xx){
                if(length(xx) > 1){
                  return(c(NA)) #drop ambiguous data, known issue with ISCN
                }else{
                  return(xx)
                }
              }) |>
  filter(!is.na(value)) |>
  mutate(value = as.numeric(value)) |>
  #filter(value > 0 & value < 2.65) |> #bound the bulk density of quartz
  full_join(mapping_bulk_density |>
              select(study_id, of_variable, header_str), by = join_by(study_id, of_variable)) |>
  mutate(temp = paste(value, note, sep = ":::")) |>
  select(ends_with('_id'), header_str, temp) |>
  pivot_wider(names_from = header_str, values_from = temp) |>
  separate_wider_delim(bulk_density_fine, delim = ":::", 
                       names = c('bulk_density_fine', 'bulk_density_fine.note')) |>
  separate_wider_delim(bulk_density_whole, delim = ":::", 
                       names = c('bulk_density_whole', 'bulk_density_whole.note')) |>
  separate_wider_delim(bulk_density_unknown, delim = ":::", 
                       names = c('bulk_density_unknown', 'bulk_density_unknown.note')) |>
  mutate(across(.cols = c(bulk_density_fine, bulk_density_whole, bulk_density_unknown),
                as.numeric))

metaBulkDensity <- mapping_bulk_density |>
  select(study_id, column_id = header_str, of_variable = header_str, description, method, unit) |>
  pivot_longer(cols = c('description', 'method', 'unit'), 
               names_to = 'is_type',
               values_to = 'with_entry') |>
  bind_rows(tribble(~study_id, ~column_id, ~of_variable, ~is_type, ~with_entry,
                    NA, "bulk_density_fine", "bulk_density_fine", 'value', '--',
                    NA, "bulk_density_fine.note", "bulk_density_fine", 'note', '--',
                    NA, "bulk_density_unknown", "bulk_density_unknown", 'value', '--',
                    NA, "bulk_density_unknown.note", "bulk_density_unknown", 'note', '--',
                    NA, "bulk_density_whole", "bulk_density_whole", 'value', '--',
                    NA, "bulk_density_whole.note", "bulk_density_whole", 'note', '--',
                    )) |>
  select(-study_id) |>
  unique() |>
  arrange(of_variable)

```

```{r}
summary(bulk_density.df)
```

```{r}
plot.df <- bulk_density.df %>%
  select(ends_with('_id'), bulk_density_whole, bulk_density_fine, bulk_density_unknown) %>%
  pivot_longer(cols = starts_with('bulk_density'), values_drop_na = TRUE)

ggplot(plot.df |>
         filter(value > 0, value < 4)) +
  geom_histogram(aes(x=value), bins = 30) +
  facet_wrap(~name, ncol = 1, scales = 'free_y')
```

```{r}
ggplot(bulk_density.df) +
  geom_point(aes(x=bulk_density_whole, y = bulk_density_fine))

ggplot(bulk_density.df) +
  geom_point(aes(x=bulk_density_whole, y = bulk_density_unknown))

ggplot(bulk_density.df) +
  geom_point(aes(x=bulk_density_fine, y = bulk_density_unknown))
```

## Soil mass fractions (organic carbon, inorganic carbon, coarse)

```{r}
ref <- allmeta.df |>
  dplyr::filter(of_variable %in% c('inorganic_carbon', 'carbon_fraction', 'coarse_fraction',
                                   'organic_carbon', 'coarse_fragment')) |>
  pivot_wider(names_from = 'is_type', values_from = 'with_entry',
              values_fn = function(xx)paste(xx, collapse = ':::')) |>
  mutate(unit = 'mass percent')
```

# Reassembiling tables

```{r}
ISCN4.meta <- metaRegions.df %>%
  bind_rows(metaLatLon.df) %>%
  bind_rows(metaObsYr) %>%
  bind_rows(metaDepth.df)

ISCN4.surfaceLocation <- dataRegions.df %>%
  full_join(latLon.df, by = join_by(study_id, dataset_id, profile_id, plot_id)) %>%
  full_join(observationYr.df, by = join_by(study_id, dataset_id, profile_id, plot_id))

ISCN.layer <- depth.df %>%
  full_join(bulk_density.df, by = join_by(study_id, dataset_id, profile_id, layer_id, plot_id))
```

```{r}
summary(ISCN4.surfaceLocation)
```

```{r}
ISCN4.meta |>
  kable () |>
  #kable_paper() |>
  scroll_box(width = "100%", height = "300px")
```

# Appendix

## Read functions

```{r file=file.path(RscriptsDir, databaseReads$ISCN3)}
#| code-summary: "readISCN3"
#| code-fold: true
```

```{r file=file.path(RscriptsDir, databaseReads$FIA)}
#| code-summary: "readFIA"
#| code-fold: true
```

```{r file=file.path(RscriptsDir, databaseReads$NCSS)}
#| code-summary: "readNCSS"
#| code-fold: true
```

